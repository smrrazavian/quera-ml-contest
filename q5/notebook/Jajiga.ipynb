{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39tfTgmcbQUl"
      },
      "source": [
        "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "شبی چند؟\n",
        "</font>\n",
        "</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjtVGnSHOUDg"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "مقدمه و صورت مسئله\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "در سوال مجموعه‌داده‌ای از اقامتگاه‌های سایت جاجیگا در اخیار شما قرار داده شده است. هدف پیش‌بینی قیمت یک اقامتگاه با توجه به ویژگی‌ها و اطلاعات آن است.\n",
        "    \n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9dy0ev-PxV1"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "وارد کردن کتابخانه‌های مورد نیاز\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    ابتدا کتابخانه‌های مورد نیازتان را وارد کنید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "qEm12Y9mOkER"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import ast\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZelMWtQP2cl"
      },
      "source": [
        "\n",
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "معرفی مجموعه داده\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "     مجموعه داده‌ی آموزش شامل ۴۷۷۶ سطر و ۴۴ ستون است. شرح این ستون‌ها در ادامه آمده است.\n",
        "     </p>\n",
        "</font>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "\n",
        "\n",
        "<center>\n",
        "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    \n",
        "|ستون|توضیحات|\n",
        "|:------:|:---:|\n",
        "|<code>id</code>|شناسه منحصر به فرد برای هر اقامتگاه|\n",
        "|<code>status</code>|وضعیت فعلی اقامتگاه (فعال یا غیرفعال)|\n",
        "|<code>title</code>|عنوان اقامتگاه|\n",
        "|<code>description</code>|شرح اقامتگاه|\n",
        "|<code>allocation</code>|نوع اجاره (کل مکان یا اتاق خصوصی)|\n",
        "|<code>types</code>|دسته‌ها یا انواع اقامتگاه (به عنوان مثال، کلبه، آپارتمان و ...)|\n",
        "|<code>regions</code>|مناطقی که اقامتگاه در آن قرار دارد (به عنوان مثال، جنگل، حومه و ...)|\n",
        "|<code>floor_area</code>|متراژ زمین اقامتگاه بر حسب متر مربع|\n",
        "|<code>land_area</code>|متراژ زیربنا اقامتگاه بر حسب متر مربع|\n",
        "|<code>floors_count</code>|تعداد طبقات اقامتگاه|\n",
        "|<code>bedrooms</code>|تعداد اتاق خواب|\n",
        "|<code>sleep_arrange</code>|چیدمان فضاهای خواب (به عنوان مثال، تخت، تشک و ..).|\n",
        "|<code>sleep_description</code>|شرح فضاهای خواب|\n",
        "|<code>guest_number</code>|تعداد مهمانانی که اقامتگاه می‌تواند در خود جای دهد|\n",
        "|<code>max_guest_number</code>|حداکثر تعداد مهمان مجاز|\n",
        "|<code>stays_min</code>|حداقل تعداد شب مورد نیاز برای رزرو|\n",
        "|<code>stays_max</code>|حداکثر تعداد شب‌های مجاز برای رزرو|\n",
        "|<code>entrance_time_min</code>|زودترین زمان ورود|\n",
        "|<code>entrance_time_max</code>|آخرین زمان ورود|\n",
        "|<code>leaving_time</code>|زمان خروج|\n",
        "|<code>features</code>|امکانات و ویژگی های موجود (به عنوان مثال، Wi-Fi، پارکینگ و ...)|\n",
        "|<code>additional_feature</code>|ویژگی‌های اضافی که تحت ویژگی‌های اصلی پوشش داده نمی‌شوند|\n",
        "|<code>additional_safety</code>|ویژگی‌های ایمنی (به عنوان مثال، آشکارسازهای دود، کپسول‌های آتش‌نشانی و ...)|\n",
        "|<code>rules</code>|قوانین خانه (مانند حیوانات خانگی ممنوع، سیگار کشیدن ممنوع و ...)|\n",
        "|<code>additional_rule</code>|قوانین اضافی تحت قوانین اصلی پوشش داده نمی‌شوند|\n",
        "|<code>min_price</code>|حداقل قیمت برای اجاره‌ی اقامتگاه|\n",
        "|<code>is_clean</code>|این که آیا اقامتگاه به عنوان تمیز علامت گذاری شده است|\n",
        "|<code>is_new</code>|این که آیا اقامتگاه جدید است|\n",
        "|<code>is_instant</code>|اینکه آیا رزرو فوری در دسترس است|\n",
        "|<code>is_plus</code>|اینکه آیا اقامتگاه ممتاز است|\n",
        "|<code>geo.lat</code>|عرض جغرافیایی ملک|\n",
        "|<code>geo.lng</code>|طول جغرافیایی ملک|\n",
        "|<code>province.id</code>|شناسه منحصر به فرد برای استان|\n",
        "|<code>province.name</code>|نام استان|\n",
        "|<code>province.url</code>|آدرس صفحه‌ی استان|\n",
        "|<code>city.id</code>|شناسه منحصر به فرد برای شهر|\n",
        "|<code>city.name</code>|نام شهر|\n",
        "|<code>city.url</code>|آدرس صفحه‌ی شهر|\n",
        "|<code>ratings.count</code>|تعداد امتیازهای دریافت شده|\n",
        "|<code>ratings.total</code>|امتیاز کل|\n",
        "|<code>ratings.cleanliness</code>|نمره‌ی تمیزی|\n",
        "|<code>ratings.location</code>|امتیاز موقعیت مکانی|\n",
        "|<code>ratings.checkin</code>|امتیاز فرایند ورود|\n",
        "|<code>ratings.value</code>|امتیاز ارزش به نسبت قیمت|\n",
        "</font>\n",
        "</div>\n",
        "</center>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "هدف شما در این مسئه پیش‌بینی مقدار <code>min_price</code> است.\n",
        "     مجموعه‌ی آزمون (تست) مانند مجموعه‌ی آموزش است با این تفاوت که ستون <code>min_price</code> را ندارد.\n",
        "</font>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;font-size:medium\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7vRr_C4PrPv"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "خواندن مجموعه داده\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    در ابتدا نیاز است فایل‌های مجموعه‌داده را بخوانید. نمونه‌های آموزشی در فایل <code>train.csv</code> و نمونه‌های آزمون که باید مقدار متغیر هدف آن‌ها را پیش‌بینی کنید در فایل <code>test.csv</code> ذخیره شده‌اند. اگر لازم دانستید می‌توانید به دلخواه خود بخشی از مجموعه‌ی آموزش را به عنوان مجموعه‌ی اعتبارسنجی نیز جدا کنید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0Bo84hGPt0w"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('../data/train.csv')\n",
        "test_data = pd.read_csv('../data/test.csv')\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data[\"allocation\"].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data[\"types\"] = [ast.literal_eval(i) for i in train_data[\"types\"]]\n",
        "train_data.loc[0][\"types\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set([item for sublist in train_data[\"types\"].apply(list) for item in sublist])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(train_data.loc[0][\"regions\"])\n",
        "train_data[\"regions\"] = [ast.literal_eval(i) for i in train_data[\"regions\"]]\n",
        "train_data[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set([item for sublist in train_data[\"regions\"].apply(list) for item in sublist])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {},
      "outputs": [],
      "source": [
        "def aggregate_sleep_arrange(sleep_arrange_str):\n",
        "    sleep_arrange_list = ast.literal_eval(sleep_arrange_str)\n",
        "\n",
        "    total_single = 0\n",
        "    total_double = 0\n",
        "    total_mattress = 0\n",
        "\n",
        "    for item in sleep_arrange_list:\n",
        "        total_single += item.get(\"single\", 0)\n",
        "        total_double += item.get(\"double\", 0)\n",
        "        total_mattress += item.get(\"mattress\", 0)\n",
        "\n",
        "    return total_single, total_double, total_mattress\n",
        "\n",
        "def extract_feature_names(features_str):\n",
        "    features_list = ast.literal_eval(features_str)\n",
        "    \n",
        "    return [feature['name'] for feature in features_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 461,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>floor_area</th>\n",
              "      <th>land_area</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>guest_number</th>\n",
              "      <th>max_guest_number</th>\n",
              "      <th>stays_min</th>\n",
              "      <th>entrance_time_min</th>\n",
              "      <th>entrance_time_max</th>\n",
              "      <th>leaving_time</th>\n",
              "      <th>min_price</th>\n",
              "      <th>...</th>\n",
              "      <th>forest</th>\n",
              "      <th>urban</th>\n",
              "      <th>shared_place</th>\n",
              "      <th>entire_place</th>\n",
              "      <th>shared_room</th>\n",
              "      <th>private_room</th>\n",
              "      <th>smoke</th>\n",
              "      <th>party</th>\n",
              "      <th>unmarried</th>\n",
              "      <th>pet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>1200</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80</td>\n",
              "      <td>1000</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1600000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>450</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>730000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>110</td>\n",
              "      <td>1000</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>24</td>\n",
              "      <td>12</td>\n",
              "      <td>3000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>2300000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4771</th>\n",
              "      <td>120</td>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>24</td>\n",
              "      <td>12</td>\n",
              "      <td>2000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4772</th>\n",
              "      <td>25</td>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>3414000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4773</th>\n",
              "      <td>80</td>\n",
              "      <td>300</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2800000</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4774</th>\n",
              "      <td>110</td>\n",
              "      <td>630</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>2200000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4775</th>\n",
              "      <td>58</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>24</td>\n",
              "      <td>12</td>\n",
              "      <td>1200000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4776 rows × 94 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      floor_area  land_area  bedrooms  guest_number  max_guest_number  \\\n",
              "0             60       1200         1             2                 3   \n",
              "1             80       1000         2             5                10   \n",
              "2             60        450         1             2                 6   \n",
              "3            110       1000         1             6                 8   \n",
              "4             14        234         0             2                 2   \n",
              "...          ...        ...       ...           ...               ...   \n",
              "4771         120        500         2             4                10   \n",
              "4772          25        500         0             4                 5   \n",
              "4773          80        300         2             4                 8   \n",
              "4774         110        630         2             4                10   \n",
              "4775          58        400         0             4                 6   \n",
              "\n",
              "      stays_min  entrance_time_min  entrance_time_max  leaving_time  \\\n",
              "0             1                 14                  0            12   \n",
              "1             1                 14                  0            12   \n",
              "2             1                 14                  0            12   \n",
              "3             1                 14                 24            12   \n",
              "4             1                 14                 23            12   \n",
              "...         ...                ...                ...           ...   \n",
              "4771          1                 14                 24            12   \n",
              "4772          1                 14                  0            12   \n",
              "4773          1                 14                  0            12   \n",
              "4774          1                 14                 23            12   \n",
              "4775          1                 14                 24            12   \n",
              "\n",
              "      min_price  ...  forest  urban  shared_place  entire_place  shared_room  \\\n",
              "0       1500000  ...       0      0             0             1            0   \n",
              "1       1600000  ...       0      0             0             1            0   \n",
              "2        730000  ...       0      1             0             1            0   \n",
              "3       3000000  ...       0      0             0             1            0   \n",
              "4       2300000  ...       0      1             0             0            0   \n",
              "...         ...  ...     ...    ...           ...           ...          ...   \n",
              "4771    2000000  ...       0      0             0             1            0   \n",
              "4772    3414000  ...       0      1             0             0            0   \n",
              "4773    2800000  ...       1      0             0             1            0   \n",
              "4774    2200000  ...       0      0             0             1            0   \n",
              "4775    1200000  ...       0      0             0             1            0   \n",
              "\n",
              "      private_room  smoke  party  unmarried  pet  \n",
              "0                0      0      0          0    1  \n",
              "1                0      1      0          0    1  \n",
              "2                0      1      0          0    1  \n",
              "3                0      0      1          0    1  \n",
              "4                1      1      1          1    1  \n",
              "...            ...    ...    ...        ...  ...  \n",
              "4771             0      0      0          1    1  \n",
              "4772             1      1      1          1    1  \n",
              "4773             0      1      1          0    1  \n",
              "4774             0      0      0          0    0  \n",
              "4775             0      0      0          0    1  \n",
              "\n",
              "[4776 rows x 94 columns]"
            ]
          },
          "execution_count": 461,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "# scaler_y = MinMaxScaler()\n",
        "\n",
        "\n",
        "def inverse_transform_min_price(normalized_price):\n",
        "    \"\"\"Inverse transform the normalized min_price to its original value\"\"\"\n",
        "    return scaler_y.inverse_transform(normalized_price.reshape(-1, 1))\n",
        "\n",
        "\n",
        "def preprocess(df: pd.DataFrame, df_type=\"train\") -> pd.DataFrame:\n",
        "    df.drop(\n",
        "        columns=[\n",
        "            \"id\",\n",
        "            \"Unnamed: 0\",\n",
        "            \"title\",\n",
        "            \"description\",\n",
        "            \"province.id\",\n",
        "            \"province.url\",\n",
        "            \"province.name\",\n",
        "            \"city.url\",\n",
        "            \"city.id\",\n",
        "            \"city.name\",\n",
        "            \"floors_count\",\n",
        "            \"additional_rule\",\n",
        "            \"sleep_description\",\n",
        "            \"stays_max\",\n",
        "            \"additional_safety\",\n",
        "            \"sleep_description\",\n",
        "            \"additional_feature\",\n",
        "            \"status\",\n",
        "            # New\n",
        "            # \"leaving_time\",\n",
        "            # \"entrance_time_max\",\n",
        "            # \"entrance_time_min\",\n",
        "            # \"units_count\",\n",
        "        ],\n",
        "        inplace=True,\n",
        "    )\n",
        "\n",
        "    df[\"types\"] = [ast.literal_eval(i) for i in df[\"types\"]]\n",
        "    df[\"regions\"] = [ast.literal_eval(i) for i in df[\"regions\"]]\n",
        "    df[[\"total_single\", \"total_double\", \"total_mattress\"]] = (\n",
        "        df[\"sleep_arrange\"].apply(aggregate_sleep_arrange).apply(pd.Series)\n",
        "    )\n",
        "    df.drop(columns=[\"sleep_arrange\"], inplace=True)\n",
        "    types = set([item for sublist in df[\"types\"].apply(list) for item in sublist])\n",
        "    regions = set([item for sublist in df[\"regions\"].apply(list) for item in sublist])\n",
        "\n",
        "    df[\"rules\"] = df[\"rules\"].apply(ast.literal_eval)\n",
        "    rules = set([item for sublist in df[\"rules\"] for item in sublist])\n",
        "    allocations = set(df[\"allocation\"])\n",
        "\n",
        "    df[\"feature_names\"] = df[\"features\"].apply(extract_feature_names)\n",
        "    df_one_hot = df[\"feature_names\"].str.join(\"|\").str.get_dummies()\n",
        "    df = pd.concat([df, df_one_hot], axis=1)\n",
        "    df.drop(columns=[\"feature_names\", \"features\"], inplace=True)\n",
        "    for t in types:\n",
        "        df[t] = df[\"types\"].apply(lambda x: t in x).astype(int)\n",
        "    for r in regions:\n",
        "        df[r] = df[\"regions\"].apply(lambda x: r in x).astype(int)\n",
        "\n",
        "    for a in allocations:\n",
        "        df[a] = (df[\"allocation\"] == a).astype(int)\n",
        "    for r in rules:\n",
        "        df[r] = df[\"rules\"].apply(lambda x: r in x).astype(int)\n",
        "\n",
        "    df = df.drop(columns=[\"types\", \"regions\", \"allocation\", \"rules\"])\n",
        "\n",
        "    norm_cols = [\n",
        "        \"geo.lat\",\n",
        "        \"geo.lng\",\n",
        "        # \"land_area\",\n",
        "        # \"floor_area\",\n",
        "        # \"units_count\"\n",
        "    ]\n",
        "    df[norm_cols] = scaler.fit_transform(df[norm_cols])\n",
        "\n",
        "    # if df_type == \"train\":\n",
        "    #     y = df[\"min_price\"].values.reshape(-1, 1)\n",
        "    #     df[\"min_price\"] = scaler_y.fit_transform(y)\n",
        "\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == bool:\n",
        "            df[col] = df[col].astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "train_data = pd.read_csv(\"../data/train.csv\")\n",
        "df = preprocess(train_data)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFiZm-LxYMrB"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "پیش‌پردازش و مهندسی ویژگی\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    در این سوال شما می‌توانید از هر تکنیک پیش‌پردازش یا مهندسی ویژگی، استفاده کنید.\n",
        "    <br>\n",
        "    تکنیک‌هایی که استفاده می‌کنید به شکل مستقیم مورد ارزیابی توسط سامانه داوری قرار <b>نمی‌گیرند.</b> بلکه همه آن‌ها در دقت مدل شما تاثیر خواهند گذاشت.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# corr_matrix = df.corr()\n",
        "# plt.figure(figsize=(20, 15))\n",
        "# sns.heatmap(corr_matrix, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = df.drop(\"min_price\", axis=1)\n",
        "y = df[\"min_price\"]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tHaVKFyYdxr"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "مدل‌سازی\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "پس از پاکسازی داده‌ها و احتمالا حذف بعضی ستون‌ها یا افزودن ویژگی‌های جدید، حال وقت آن است که مطابق سلیقه‌ی خود، مدل مناسب را با استفاده از داده‌های پیش‌پردازش شده آموزش دهید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLoHLZkUYm8Q"
      },
      "source": [
        "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "معیار ارزیابی\n",
        "</font>\n",
        "</h3>\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    در این سوال از معیار  R2 Score جهت ارزیابی نتایج مدل شما استفاده خواهد شد.\n",
        "    در سامانه داوری هم از این معیار برای نمره‌دهی استفاده شده است.\n",
        "    <br>\n",
        "    پیشنهاد می‌شود با توجه به این معیار، عملکرد مدل خود را بر روی مجموعه‌ی آموزش یا اعتبارسنجی ارزیابی کنید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 474,
      "metadata": {
        "id": "MjP1etskYtjC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.6; total time=   4.3s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.6; total time=   4.5s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.6; total time=   4.1s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.8; total time=   3.3s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.8; total time=   3.0s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.8; total time=   3.4s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.6; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.6; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.6; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=2000, subsample=0.6; total time=   3.5s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=2000, subsample=0.6; total time=   4.0s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=2000, subsample=0.6; total time=   2.8s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=2000, subsample=0.8; total time=   3.6s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=2000, subsample=0.8; total time=   2.9s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=2000, subsample=0.8; total time=   3.2s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.6; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.6; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.6; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   2.0s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.6; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.6; total time=   3.9s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.6; total time=   3.8s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.6; total time=   4.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.8; total time=   4.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.8; total time=   5.8s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=2000, subsample=0.8; total time=   4.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.6; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.6; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.6; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   2.0s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.6; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8; total time=   1.2s\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [2000, 300],\n",
        "    \"max_depth\": [8, 3],\n",
        "    \"learning_rate\": [0.01 , 0.1],\n",
        "    \"subsample\": [0.6, 0.8],\n",
        "    \"colsample_bytree\": [0.6, 0.8],\n",
        "}\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    objective=\"reg:squarederror\",\n",
        ")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"r2\",\n",
        "    verbose=2,\n",
        "    n_jobs=1,\n",
        ")\n",
        "\n",
        "grid_search.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyWHmH6qY3Ug"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font color=\"red\"><b color='red'>توجه:</b></font>\n",
        "<font face=\"vazir\" size=3>\n",
        " جهت کسب امتیاز نیاز است تا پاسخ شما حداقل امتیاز <code>50</code> را با توجه به معیار معرفی‌شده کسب نماید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 473,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 2000, 'subsample': 0.6}\n",
            "0.68821914990743\n",
            "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             gamma=None, grow_policy=None, importance_type=None,\n",
            "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
            "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "             multi_strategy=None, n_estimators=2000, n_jobs=None,\n",
            "             num_parallel_tree=None, random_state=None, ...)\n",
            "{'mean_fit_time': array([3.84475795, 0.65118567, 1.66245174, 0.51406113, 1.27657461,\n",
            "       0.28853575, 0.82768377, 0.24037782]), 'std_fit_time': array([0.30570336, 0.08902376, 0.26650773, 0.06863857, 0.05273998,\n",
            "       0.08044812, 0.34009324, 0.04871673]), 'mean_score_time': array([0.0471611 , 0.02768691, 0.03175068, 0.03007436, 0.02480674,\n",
            "       0.02545865, 0.02333458, 0.02340484]), 'std_score_time': array([0.00501769, 0.00099268, 0.00603603, 0.00488211, 0.00420089,\n",
            "       0.0063844 , 0.00253486, 0.00540447]), 'param_colsample_bytree': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6],\n",
            "             mask=[False, False, False, False, False, False, False, False],\n",
            "       fill_value=1e+20), 'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
            "             mask=[False, False, False, False, False, False, False, False],\n",
            "       fill_value=1e+20), 'param_max_depth': masked_array(data=[8, 8, 8, 8, 3, 3, 3, 3],\n",
            "             mask=[False, False, False, False, False, False, False, False],\n",
            "       fill_value=999999), 'param_n_estimators': masked_array(data=[2000, 300, 800, 200, 2000, 300, 800, 200],\n",
            "             mask=[False, False, False, False, False, False, False, False],\n",
            "       fill_value=999999), 'param_subsample': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6],\n",
            "             mask=[False, False, False, False, False, False, False, False],\n",
            "       fill_value=1e+20), 'params': [{'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 2000, 'subsample': 0.6}, {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300, 'subsample': 0.6}, {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 800, 'subsample': 0.6}, {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 200, 'subsample': 0.6}, {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 2000, 'subsample': 0.6}, {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.6}, {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 800, 'subsample': 0.6}, {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.6}], 'split0_test_score': array([0.68228191, 0.64824653, 0.67862678, 0.61119223, 0.66675138,\n",
            "       0.59478188, 0.64905947, 0.55153996]), 'split1_test_score': array([0.70732635, 0.66989088, 0.70415419, 0.63073039, 0.67885745,\n",
            "       0.57528508, 0.64641082, 0.53096366]), 'split2_test_score': array([0.67504919, 0.63654959, 0.67079413, 0.59537667, 0.66369605,\n",
            "       0.56813025, 0.64075607, 0.51808643]), 'mean_test_score': array([0.68821915, 0.65156233, 0.68452503, 0.6124331 , 0.66976829,\n",
            "       0.57939907, 0.64540879, 0.53353002]), 'std_test_score': array([0.01382973, 0.01381198, 0.01424349, 0.01445974, 0.00654692,\n",
            "       0.01126265, 0.00346311, 0.01377738]), 'rank_test_score': array([1, 4, 2, 6, 3, 7, 5, 8], dtype=int32)}\n",
            "247.5\n"
          ]
        }
      ],
      "source": [
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n",
        "print(grid_search.best_estimator_)\n",
        "print(grid_search.cv_results_)\n",
        "\n",
        "\n",
        "# r2\n",
        "y_pred = grid_search.predict(X_test)\n",
        "r2score = r2_score(y_test, y_pred)\n",
        "print(round(r2score, 3) * 250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 465,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[465], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Grid Search Catboost\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m600\u001b[39m],\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.01\u001b[39m],\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m8\u001b[39m],\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2_leaf_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m     11\u001b[0m }\n",
            "File \u001b[0;32m/data/quera/ml-contest/.venv/lib/python3.10/site-packages/catboost/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     FeaturesData, EFstrType, EShapCalcType, EFeaturesSelectionAlgorithm, EFeaturesSelectionGrouping,\n\u001b[1;32m      3\u001b[0m     Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatBoostRanker, CatBoostError, cv, sample_gaussian_process, train,\n\u001b[1;32m      4\u001b[0m     sum_models, _have_equal_features, to_regressor, to_classifier, to_ranker, MultiRegressionCustomMetric,\n\u001b[1;32m      5\u001b[0m     MultiRegressionCustomObjective, MultiTargetCustomMetric, MultiTargetCustomObjective\n\u001b[1;32m      6\u001b[0m )  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VERSION \u001b[38;5;28;01mas\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeaturesData\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFstrType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEShapCalcType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionAlgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionGrouping\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPool\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRegressor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRanker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatboostError\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomMetric\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomObjective\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m ]\n",
            "File \u001b[0;32m/data/quera/ml-contest/.venv/lib/python3.10/site-packages/catboost/core.py:45\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_plot_file, try_plot_offline, OfflineMetricVisualizer\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuiltinMetric\n",
            "File \u001b[0;32m/data/quera/ml-contest/.venv/lib/python3.10/site-packages/catboost/plot_helpers.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[1;32m      6\u001b[0m fspath \u001b[38;5;241m=\u001b[39m _catboost\u001b[38;5;241m.\u001b[39mfspath\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_plot_offline\u001b[39m(figs):\n",
            "File \u001b[0;32m_catboost.pyx:1\u001b[0m, in \u001b[0;36minit _catboost\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "# Grid Search Catboost\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from catboost import CatBoostRegressor\n",
        "import pandas as pd\n",
        "\n",
        "param_grid = {\n",
        "    \"iterations\": [500, 600],\n",
        "    \"learning_rate\": [0.1, 0.01],\n",
        "    \"depth\": [8],\n",
        "    \"l2_leaf_reg\": [1, 3],\n",
        "}\n",
        "\n",
        "catboost_model = CatBoostRegressor(\n",
        "    loss_function=\"RMSE\",\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "\n",
        "grid_search_cat = GridSearchCV(\n",
        "    estimator=catboost_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring=\"f1_macro\",\n",
        "    verbose=2,\n",
        "    n_jobs=1,\n",
        ")\n",
        "\n",
        "grid_search_cat.fit(X, y)\n",
        "\n",
        "print(\"Best Hyperparameters: \", grid_search_cat.best_params_)\n",
        "print(\"Best Score: \", grid_search_cat.best_score_)\n",
        "\n",
        "best_model = grid_search_cat.best_estimator_\n",
        "\n",
        "feature_importances = pd.Series(best_model.feature_importances_, index=X_train.columns)\n",
        "important_features = feature_importances.sort_values(ascending=False)\n",
        "important_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNcSEtXoyhMv"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        " پیش‌بینی بر روی داده‌ی آزمون و خروجی\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    پیش‌بینی مدل خود بر روی داده‌های آزمون را در یک دیتافریم (<code>dataframe</code>) به فرمت زیر ذخیره کنید.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    توجه داشته باشید که نام دیتافریم باید <code>submission</code> باشد؛ در غیر این‌صورت، سامانه‌ی داوری قادر به ارزیابی خروجی شما نخواهد بود.\n",
        "    این دیتافریم تنها شامل ۱ ستون با اسم <code>min_price</code> است.\n",
        "    <br>\n",
        "    به ازای هر سطر موجود در دیتافریم <code>test</code>، باید یک مقدار پیش‌بینی‌شده داشته باشید.\n",
        "    به‌عنوان مثال جدول زیر، ۵ سطر ابتدایی دیتافریم <code>submission</code> را نشان می‌دهد. البته در جواب شما، اعداد ستون <code>min_price</code> ممکن است متفاوت باشد.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<center>\n",
        "<div style=\"direction: ltr;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    \n",
        "||<code>min_price</code>|\n",
        "|:----:|:-----:|\n",
        "|0|700000|\n",
        "|1|650000|\n",
        "|2|5000000|\n",
        "|3|800000|\n",
        "|4|750000|\n",
        "\n",
        "</font>\n",
        "</div>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def preprocess(train_data):\n",
        "#     columns_to_drop = [\n",
        "#         \"id\",\n",
        "#         \"city.url\",\n",
        "#         \"city.id\",\n",
        "#         \"city.name\",\n",
        "#         \"title\",\n",
        "#         \"description\",\n",
        "#         \"province.url\",\n",
        "#         \"province.name\",\n",
        "#         \"province.id\",\n",
        "#         \"sleep_description\",\n",
        "#         \"floors_count\",\n",
        "#     ]\n",
        "#     train_data.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
        "#     numerical_data = train_data.select_dtypes(include=[int, float])\n",
        "#     numerical_data.fillna(numerical_data.mean(), inplace=True)\n",
        "#     return numerical_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 467,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns = list(df.columns)\n",
        "columns.remove(\"min_price\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 466,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1194\n"
          ]
        }
      ],
      "source": [
        "test_data = pd.read_csv('../data/test.csv')\n",
        "\n",
        "df_test = preprocess(test_data, \"test\")\n",
        "print(len(df_test))\n",
        "for col in df.columns:\n",
        "    if col not in df_test.columns:\n",
        "        df_test[col] = 0\n",
        "\n",
        "df_test = df_test[columns]\n",
        "\n",
        "# Predict\n",
        "y_pred = grid_search.predict(df_test)\n",
        "# y_pred = inverse_transform_min_price(y_pred)\n",
        "test_data[\"min_price\"] = y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 469,
      "metadata": {
        "id": "rJuhMbbHY7-f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       1.313214e+06\n",
              "1       1.345590e+06\n",
              "2       9.471978e+05\n",
              "3       1.180617e+06\n",
              "4       1.005655e+06\n",
              "            ...     \n",
              "1189    1.503132e+06\n",
              "1190    1.121990e+06\n",
              "1191    1.408183e+06\n",
              "1192    4.650156e+06\n",
              "1193    9.308427e+05\n",
              "Name: min_price, Length: 1194, dtype: float32"
            ]
          },
          "execution_count": 469,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To-Do\n",
        "submission = test_data[\"min_price\"]\n",
        "submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHGyEstwzlc3"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "<b>سلول جواب‌ساز</b>\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا در صورت نیاز به پشتیبانی امکان بررسی کد شما وجود داشته باشد.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 470,
      "metadata": {
        "id": "LWuqWi46zi_-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File Paths:\n",
            "['submission.csv', 'Jajiga.ipynb']\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "def compress(file_names):\n",
        "    print(\"File Paths:\")\n",
        "    print(file_names)\n",
        "    compression = zipfile.ZIP_DEFLATED\n",
        "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
        "        for file_name in file_names:\n",
        "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "file_names = ['submission.csv', 'Jajiga.ipynb']\n",
        "compress(file_names)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
